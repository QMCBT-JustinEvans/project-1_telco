{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31f48ff2",
   "metadata": {},
   "source": [
    "######################### EXPLORE #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e93c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS NEEDED FOR EXPLORATION\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21e91dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_toc ():\n",
    "    \"\"\"\n",
    "    PRINT TABLE OF CONTENTS FOR CUSTOM EXPLORE FUNCTIONS\n",
    "    \"\"\"\n",
    "    print(\"** CUSTOM EXPLORATION FUNCTIONS\")\n",
    "    \n",
    "    print(\"explore_tips: PRINT A LIST OF USEFUL FUNCTIONS, METHODS, AND ATTRIBUTES USED FOR EXPLORATION\")\n",
    "    print(\"nunique_column_all(df): PRINT NUNIQUE OF ALL COLUMNS\")\n",
    "    print(\"nunique_column_objects(df): PRINT NUNIQUE OF COLUMNS THAT ARE OBJECTS\")\n",
    "    print(\"nunique_column_qty(df): PRINT NUNIQUE OF COLUMNS THAT ARE *NOT* OBJECTS\")\n",
    "    print(\"numeric_range(df): COMPUTE RANGE FOR ALL NUMERIC VARIABLES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edbbb123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_tips():\n",
    "\n",
    "    \"\"\"\n",
    "    PRINT A LIST OF USEFUL FUNCTIONS, METHODS, AND ATTRIBUTES USED FOR EXPLORATION\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"** USEFUL EXPLORATORY CODE**\")\n",
    "    print (\"DFNAME.head()\")\n",
    "    print (\"DFNAME.shape\")\n",
    "    print (\"DFNAME.shape[0] #read row count\")\n",
    "    print (\"DFNAME.describe().T\")\n",
    "    print (\"DFNAME.columns.to_list()\")\n",
    "    print(\"DFNAME.COLUMNNAME.value_counts(dropna=False)\")\n",
    "    print (\"DFNAME.dtypes\")\n",
    "    print(\"DFNAME.select_dtypes(include='object').columns\")\n",
    "    print(\"DFNAME.select_dtypes(include='float').columns\")\n",
    "    print(\"pd.crosstab(DFNAME.COLUMN-1, DFNAME.COLUMN-2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d058103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT NUNIQUE OF ALL COLUMNS\n",
    "\n",
    "def nunique_column_all(df):\n",
    "    for col in df.columns:\n",
    "        print(df[col].value_counts())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c036dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT NUNIQUE OF COLUMNS THAT ARE OBJECTS\n",
    "\n",
    "def nunique_column_objects(df): \n",
    "    for col in df.columns:\n",
    "        if df[col].dtypes == 'object':\n",
    "            print(f'{col} has {df[col].nunique()} unique values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d84c8911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT NUNIQUE OF COLUMNS THAT ARE *NOT* OBJECTS\n",
    "\n",
    "def nunique_column_qty(df): \n",
    "    for col in df.columns:\n",
    "        if df[col].dtypes != 'object':\n",
    "            print(f'{col} has {df[col].nunique()} unique values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad03a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **COMPUTE RANGE FOR ALL NUMERIC VARIABLES**\n",
    "\n",
    "def numeric_range(df):\n",
    "    numeric_list = df.select_dtypes(include = 'float').columns.tolist()\n",
    "    numeric_range = df[numeric_list].describe().T\n",
    "    numeric_range['range'] = numeric_range['max'] - numeric_range['min']\n",
    "    return numeric_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD A FUNCTION THAT DOES THIS FOR ALL \"FLOAT\" COLUMNS\n",
    "\n",
    "# float_cols = train_iris.select_dtypes(include='float').columns\n",
    "\n",
    "# Plot numeric columns\n",
    "#plot_float_cols = float_cols \n",
    "#for col in plot_float_cols:\n",
    "#    plt.hist(train_iris[col])\n",
    "#    plt.title(col)\n",
    "#    plt.show()\n",
    "#    plt.boxplot(train_iris[col])\n",
    "#    plt.title(col)\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79191946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD A FUNCTION THAT DOES THIS FOR ALL \"OBJECT\" COLUMNS\n",
    "\n",
    "# train.species.value_counts()\n",
    "# plt.hist(train_iris.species_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5d9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD A FUNCTION THAT DOES THIS\n",
    "\n",
    "#test_var = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "#for var in test_var:\n",
    "#    t_stat, p_val = t_stat, p_val = stats.mannwhitneyu(virginica[var], versicolor[var], alternative=\"two-sided\")\n",
    "#    print(f'Comparing {var} between Virginica and Versicolor')\n",
    "#    print(t_stat, p_val)\n",
    "#    print('')\n",
    "#    print('---------------------------------------------------------------------')\n",
    "#    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd647797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(DF, hue='TARGET_COLUMN', corner=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce342ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD A FUNCTION; This will list out Accuracies for each model\n",
    "\n",
    "# accuracy_dictionary = {'Baseline': (petpics_df.actual == petpics_df.baseline).mean(), \n",
    "#                   'Model_1 accuracy': (petpics_df.actual == petpics_df.model1).mean(),\n",
    "#                   'Model_2 accuracy': (petpics_df.actual == petpics_df.model2).mean(),\n",
    "#                   'Model_3 accuracy': (petpics_df.actual == petpics_df.model3).mean(),\n",
    "#                   'Model_4 accuracy': (petpics_df.actual == petpics_df.model4).mean()}\n",
    "# accuracy_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e08eb8e",
   "metadata": {},
   "source": [
    "```\n",
    "{'Baseline': 0.6508,\n",
    " 'Model_1 accuracy': 0.8074,\n",
    " 'Model_2 accuracy': 0.6304,\n",
    " 'Model_3 accuracy': 0.5096,\n",
    " 'Model_4 accuracy': 0.7426}\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754151b3",
   "metadata": {},
   "source": [
    "######################### EVALUATE #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6b778ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS NEEDED FOR EVALUATION\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "407b8827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_toc ():\n",
    "    \"\"\"\n",
    "    PRINT TABLE OF CONTENTS FOR CUSTOM EVALUATION FUNCTIONS\n",
    "    \"\"\"\n",
    "    print(\"** CUSTOM EVALUATION FUNCTIONS\")\n",
    "    \n",
    "    print(\"eval_tips: PRINT A LIST OF USEFUL FUNCTIONS, METHODS, AND ATTRIBUTES USED FOR EXPLORATION\")\n",
    "    print(\"print_classification_metrics(actuals, predictions): PRINT CLASSIFICATION METRICS FROM CONFUSION MATRIX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "144e044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_tips():\n",
    "    \"\"\"\n",
    "    PRINT A LIST OF USEFUL FUNCTIONS, METHODS, AND ATTRIBUTES USED FOR EXPLORATION\n",
    "    \"\"\"\n",
    "    print(\"** USEFUL EXPLORATORY CODE**\")\n",
    "\n",
    "#    print (\"DFNAME.head()\")\n",
    "#    print (\"DFNAME.shape\")\n",
    "#    print (\"DFNAME.shape[0] #read row count\")\n",
    "#    print (\"DFNAME.describe().T\")\n",
    "#    print (\"DFNAME.columns.to_list()\")\n",
    "#    print(\"DFNAME.COLUMNNAME.value_counts(dropna=False)\")\n",
    "#    print (\"DFNAME.dtypes\")\n",
    "#    print(\"DFNAME.select_dtypes(include='object').columns\")\n",
    "#    print(\"DFNAME.select_dtypes(include='float').columns\")\n",
    "#    print(\"pd.crosstab(DFNAME.COLUMN-1, DFNAME.COLUMN-2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85c47a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_metrics(actuals, predictions):\n",
    "    \"\"\"\n",
    "    Stolen from Codeup Instructor Ryan McCall (Thanx, this is awesome!)\\n\n",
    "    This function extrapulates the Confusion Matrix metrics (TN, FP, FN, TP) using the method .ravel from sklearn\\n\n",
    "    then simply applies those metrics to the appropriate formulas to return Accuracy, Precision, Recall and Fl.\n",
    "    \"\"\"\n",
    "   \n",
    "    TN, FP, FN, TP = confusion_matrix(actuals, predictions).ravel()\n",
    "    ALL = TP + TN + FP + FN\n",
    "    \n",
    "    accuracy = (TP + TN)/ALL\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "    true_positive_rate = TP/(TP+FN)\n",
    "    print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "    false_positive_rate = FP/(FP+TN)\n",
    "    print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "    true_negative_rate = TN/(TN+FP)\n",
    "    print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "    false_negative_rate = FN/(FN+TP)\n",
    "    print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "    precision = TP/(TP+FP)\n",
    "    print(f\"Precision: {precision}\")\n",
    "\n",
    "    recall = TP/(TP+FN)\n",
    "    print(f\"Recall: {recall}\")\n",
    "\n",
    "    f1_score = 2*(precision*recall)/(precision+recall)\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "    support_pos = TP + FN\n",
    "    print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "    support_neg = FP + TN\n",
    "    print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4be428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wraps Codeup Instructor Ryan McCall's Classification Matrix Function into a single print event with Named Headers.\n",
    "\n",
    "# Actual = \n",
    "\n",
    "\n",
    "#print('** Baseline:')\n",
    "#print(print_classification_metrics(petpics_df.actual, petpics_df.baseline))\n",
    "\n",
    "#print('')\n",
    "#print('** Model_1:')\n",
    "#print(print_classification_metrics(petpics_df.actual, petpics_df.model1))\n",
    "\n",
    "#print('')\n",
    "#print('** Model_2:')\n",
    "#print(print_classification_metrics(petpics_df.actual, petpics_df.model2))\n",
    "\n",
    "#print('')\n",
    "#print('** Model_3:')\n",
    "#print(print_classification_metrics(petpics_df.actual, petpics_df.model3))\n",
    "\n",
    "#print('')\n",
    "#print('** Model_4:')\n",
    "#print(print_classification_metrics(petpics_df.actual, petpics_df.model4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
